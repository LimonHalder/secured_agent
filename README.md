
````markdown
# ğŸ§  Secure LangGraph Agent

A secure, modular AI agent powered by [LangChain](https://github.com/langchain-ai/langchain) and [LangGraph](https://github.com/langchain-ai/langgraph), with built-in support for tool use, threat detection, and structured logging.

## ğŸ“‚ Project Overview

This project combines the flexibility of LangChain with the stateful flow control of LangGraph. It supports:

- âœ… Secure question answering via LLM  
- ğŸ” Tool-based queries (e.g., Tavily Search)  
- âš ï¸ Threat detection and validation  
- ğŸ“Š Structured logging and error tracking  

## ğŸš€ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/LimonHalder/secured_agent.git
cd secured_agent
````

### 2. Setup Python Environment

```bash
python -m venv venv
source venv/bin/activate     # macOS/Linux
venv\Scripts\activate        # Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

Create a `.env` file in the root directory with the following:

```env
GROQ_API_KEY=your_GROQ_api_key
TAVILY_API_KEY=your_tavily_api_key
```

## ğŸ§ª Running the Agent

### â–¶ï¸ Run Main Agent (Q\&A + Tools)

To start the agent for general question-answering and tool-based tasks:

```bash
python main.py
```

This script initializes the LangGraph-powered agent and handles input/output with integrated tools.

### ğŸ›¡ï¸ Run Threat Checker

To test the agent's response to potentially malicious or suspicious inputs:

```bash
python run_threat_tests.py
```

This will trigger the security wrappers and log results accordingly.

## ğŸ§° Tech Stack

* **LangChain** â€“ LLM chains and tool integrations
* **LangGraph** â€“ State-based LLM orchestration
* **TavilySearch** â€“ External search API integration
* **Custom Wrappers** â€“ SecureAgentWrapper, threat detector
* **Python Logging** â€“ Centralized, formatted logs

## ğŸ“ File Structure

```
SECURITY_WRAPPER/
â”œâ”€â”€ config/
â”‚ â””â”€â”€ env_loader.py # Loads .env variables
â”œâ”€â”€ logger/
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ logger.py # Logging configuration
â”œâ”€â”€ orchestrator/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ agent_builder.py # Constructs LangGraph agent flow
â”‚ â”œâ”€â”€ llm_node.py # LLM-related LangGraph node logic
â”‚ â””â”€â”€ tool_initializer.py # Tool (e.g., Tavily) initialization
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ test_threat.py # Unit tests for threat checking
â”œâ”€â”€ wrapper/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ base_wrapper.py # Secure wrapper for agent protection
â”‚ â”œâ”€â”€ config.yml # Threat detection config
â”‚ â”œâ”€â”€ response_handler.py # Output post-processing logic
â”‚ â””â”€â”€ threat_detector.py # Detects malicious or unsafe queries
â”œâ”€â”€ .env # Environment variables (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py # Run the main LangGraph agent
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ security.log # Logs from threat and usage
â””â”€â”€ README.md
```

## ğŸ“„ .gitignore

```gitignore
.env
__pycache__/
*.pyc
venv/
logs/
.vscode/
```

## ğŸ“ƒ License

MIT License

```

```
